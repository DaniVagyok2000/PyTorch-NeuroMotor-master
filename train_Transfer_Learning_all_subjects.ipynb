{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from src.dataset.Moabb2BGenerator_One_Person import Moabb2BGenerator\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "\n",
    "from config.default import cfg\n",
    "\n",
    "from src.dataset.MI_dataset_single_subject import MI_Dataset as MI_Dataset_single_subject\n",
    "\n",
    "from models.conditioned_eegnet import ConditionedEEGNet\n",
    "\n",
    "from utils.eval import accuracy\n",
    "from utils.model import print_parameters\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = [1,2,3,4,5,6,7,8,9]\n",
    "batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device =  torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset: 9 samples\n"
     ]
    }
   ],
   "source": [
    "train_datasets_2b = []\n",
    "\n",
    "for subject in subjects:\n",
    "    dataset = Moabb2BGenerator(subject, return_subject_id=True, device=device,runs=[0,1,2])\n",
    "    train_datasets_2b.append(dataset)\n",
    "    channels = dataset.channels\n",
    "    time_steps = dataset.time_steps\n",
    "train_dataset_2b = ConcatDataset(train_datasets_2b)\n",
    "\n",
    "train_dataloader_2b = DataLoader(train_dataset_2b, batch_size=batch_size, shuffle=True)\n",
    "print(f\"Train dataset: {len(train_datasets_2b)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset: 9 samples\n"
     ]
    }
   ],
   "source": [
    "test_datasets_2b = []\n",
    "for subject in subjects:\n",
    "    test_datasets_2b.append(Moabb2BGenerator(subject, runs=[3,4],return_subject_id=True, device=device))\n",
    "test_dataset_2b = ConcatDataset(test_datasets_2b)\n",
    "\n",
    "test_dataloader_2b = DataLoader(test_dataset_2b, batch_size=batch_size, shuffle=False)\n",
    "print(f\"Test dataset: {len(test_datasets_2b)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset: 1296 samples\n",
      "Test dataset: 864 samples\n",
      "torch.Size([64, 3, 401])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train dataset: {len(train_dataset_2b)} samples\")\n",
    "print(f\"Test dataset: {len(test_dataset_2b)} samples\")\n",
    "\n",
    "for feature, label in train_dataloader_2b:\n",
    "    print(feature[0].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels =  channels\n",
    "samples =  time_steps\n",
    "num_classes_2b = 2\n",
    "\n",
    "# Modell betöltése 3 csatornával, 2 kimenettel\n",
    "new_eeg_model = ConditionedEEGNet( channels=channels, samples=samples, num_classes=num_classes_2b, num_subjects=len(subjects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/200, Loss: 11.29024949669838, Train accuracy: 72.53%, Test accuracy: 67.36%\n",
      "Epoch 20/200, Loss: 10.957565128803253, Train accuracy: 73.30%, Test accuracy: 67.82%\n",
      "Epoch 30/200, Loss: 11.083590507507324, Train accuracy: 73.69%, Test accuracy: 68.87%\n",
      "Epoch 40/200, Loss: 11.032596319913864, Train accuracy: 73.77%, Test accuracy: 69.10%\n",
      "Epoch 50/200, Loss: 11.10489371418953, Train accuracy: 71.68%, Test accuracy: 68.06%\n",
      "Epoch 60/200, Loss: 11.454714268445969, Train accuracy: 72.38%, Test accuracy: 67.94%\n",
      "Epoch 70/200, Loss: 11.383916020393372, Train accuracy: 70.52%, Test accuracy: 67.01%\n",
      "Epoch 80/200, Loss: 11.300152122974396, Train accuracy: 69.75%, Test accuracy: 68.40%\n",
      "Epoch 90/200, Loss: 11.205676168203354, Train accuracy: 70.91%, Test accuracy: 64.70%\n",
      "Epoch 100/200, Loss: 11.36954739689827, Train accuracy: 71.37%, Test accuracy: 66.67%\n",
      "Epoch 110/200, Loss: 11.340649604797363, Train accuracy: 70.83%, Test accuracy: 65.05%\n",
      "Epoch 120/200, Loss: 11.232110887765884, Train accuracy: 71.91%, Test accuracy: 67.94%\n",
      "Epoch 130/200, Loss: 11.234934389591217, Train accuracy: 72.38%, Test accuracy: 65.51%\n",
      "Epoch 140/200, Loss: 11.007072687149048, Train accuracy: 71.60%, Test accuracy: 64.93%\n",
      "Epoch 150/200, Loss: 11.158203065395355, Train accuracy: 73.15%, Test accuracy: 66.44%\n",
      "Epoch 160/200, Loss: 11.092271327972412, Train accuracy: 71.60%, Test accuracy: 66.78%\n",
      "Epoch 170/200, Loss: 11.319594144821167, Train accuracy: 72.84%, Test accuracy: 65.97%\n",
      "Epoch 180/200, Loss: 11.417621165513992, Train accuracy: 71.53%, Test accuracy: 67.71%\n",
      "Epoch 190/200, Loss: 11.406847953796387, Train accuracy: 71.22%, Test accuracy: 67.01%\n",
      "Epoch 200/200, Loss: 11.433369100093842, Train accuracy: 70.99%, Test accuracy: 67.01%\n",
      "##################################################\n",
      "Final_loss: 11.433369100093842\n",
      "Final train accuracy: 72.69%\n",
      "Final test accuracy: 67.94%\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(new_eeg_model.parameters(), lr=cfg['train']['learning_rate'], weight_decay=cfg['train']['weight_decay'])\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(cfg['train']['n_epochs']):\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    for batch_features, batch_labels in train_dataloader_2b:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = new_eeg_model(batch_features[0],batch_features[1])\n",
    "        loss = criterion(outputs, batch_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    if epoch % 10 == 9:\n",
    "        train_accuracy = accuracy(new_eeg_model, train_dataloader_2b)\n",
    "        test_accuracy = accuracy(new_eeg_model, test_dataloader_2b)\n",
    "        print(f\"Epoch {epoch + 1}/{cfg['train']['n_epochs']}, Loss: {epoch_loss}, Train accuracy: {train_accuracy:.2f}%, Test accuracy: {test_accuracy:.2f}%\")\n",
    "\n",
    "print(\"#\"*50)\n",
    "print(f'Final_loss: {epoch_loss}')\n",
    "print(f'Final train accuracy: {accuracy(new_eeg_model, train_dataloader_2b):.2f}%')\n",
    "print(f'Final test accuracy: {accuracy(new_eeg_model, test_dataloader_2b):.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(new_eeg_model.state_dict(), 'model_state_2b_all_subjects.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data for 2a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = [1,2,3,4,5,6,7,8,9]\n",
    "train_runs = {\n",
    "                1:[0, 1, 2, 3, 4],\n",
    "                2:[0, 1, 2, 3, 4],\n",
    "                3:[0, 1, 2, 3, 4],\n",
    "                4:[0, 1],\n",
    "                5:[0, 1, 2, 3, 4],\n",
    "                6:[0, 1, 2, 3, 4],\n",
    "                7:[0, 1, 2, 3, 4],\n",
    "                8:[0, 1, 2, 3, 4],\n",
    "                9:[0, 1, 2, 3, 4]\n",
    "        }\n",
    "test_runs = {\n",
    "                1:[5],\n",
    "                2:[5],\n",
    "                3:[5],\n",
    "                4:[2],\n",
    "                5:[5],\n",
    "                6:[5],\n",
    "                7:[5],\n",
    "                8:[5],\n",
    "                9:[5]\n",
    "}\n",
    "\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "Test dataset: 432 samples\n"
     ]
    }
   ],
   "source": [
    "test_datasets = []\n",
    "for subject in subjects:\n",
    "    test_datasets.append(MI_Dataset_single_subject(subject, test_runs[subject],return_subject_id=True, device=device, verbose=False))\n",
    "test_dataset = ConcatDataset(test_datasets)\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "print(f\"Test dataset: {len(test_dataset)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "Train dataset: 2016 samples\n"
     ]
    }
   ],
   "source": [
    "train_datasets = []\n",
    "\n",
    "for subject in subjects:\n",
    "    dataset = MI_Dataset_single_subject(subject, train_runs[subject], return_subject_id=True, device=device, verbose=False)\n",
    "    train_datasets.append(dataset)\n",
    "    channels = dataset.channels\n",
    "    time_steps = dataset.time_steps\n",
    "train_dataset = ConcatDataset(train_datasets)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "print(f\"Train dataset: {len(train_dataset)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset: 2016 samples\n",
      "Test dataset: 432 samples\n",
      "tensor([6, 4, 8, 6, 4, 0, 6, 7, 6, 2, 0, 4, 8, 2, 8, 1, 5, 8, 1, 2, 1, 1, 1, 6,\n",
      "        3, 4, 7, 4, 7, 0, 4, 0, 4, 0, 6, 8, 6, 2, 6, 8, 3, 0, 2, 2, 7, 5, 0, 5,\n",
      "        1, 7, 4, 1, 4, 4, 6, 8, 0, 7, 6, 5, 6, 1, 6, 5])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train dataset: {len(train_dataset)} samples\")\n",
    "print(f\"Test dataset: {len(test_dataset)} samples\")\n",
    "\n",
    "for feature, label in train_dataloader:\n",
    "    # print(feature[0].shape)\n",
    "    # print(feature[1].shape)\n",
    "    # print(label)\n",
    "    print(feature[1])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path: str, channels: int, samples: int, num_classes: int) -> torch.nn.Module:\n",
    "    # ConditionedEEGNet példányosítása\n",
    "    model = ConditionedEEGNet(channels=channels, samples=samples, num_classes=num_classes,num_subjects=len(subjects))\n",
    "\n",
    "    # Modell súlyainak betöltése, kihagyva az fn2 réteget\n",
    "    model_weights = torch.load(model_path, map_location=device)\n",
    "    model_weights = {k: v for k, v in model_weights.items() if 'fn2' not in k}\n",
    "    model.load_state_dict(model_weights, strict=False)\n",
    "\n",
    "    # Az fn2 réteg cseréje,4 kimenetre\n",
    "    in_features = model.fn2.in_features \n",
    "    model.fn2 = nn.Linear(in_features, 4)  \n",
    "\n",
    "    model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(model_path=\"model_state_2b_all_subjects.pth\", channels = channels, samples = samples, num_classes = 4 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eeg_processor.conv1.weight.... --> 1024\n",
      "eeg_processor.bn1.weight...... --> 16\n",
      "eeg_processor.bn1.bias........ --> 16\n",
      "eeg_processor.dw_conv1.weight. --> 96\n",
      "eeg_processor.bn2.weight...... --> 32\n",
      "eeg_processor.bn2.bias........ --> 32\n",
      "eeg_processor.sep_conv1.weight --> 512\n",
      "eeg_processor.conv2.weight.... --> 1024\n",
      "eeg_processor.bn3.weight...... --> 32\n",
      "eeg_processor.bn3.bias........ --> 32\n",
      "subject_processor.fn1.weight.. --> 144\n",
      "subject_processor.fn1.bias.... --> 16\n",
      "query.weight.................. --> 12288\n",
      "key.weight.................... --> 512\n",
      "value.weight.................. --> 12288\n",
      "fn1.weight.................... --> 4096\n",
      "fn1.bias...................... --> 128\n",
      "fn2.weight.................... --> 512\n",
      "fn2.bias...................... --> 4\n",
      "eeg_fn.weight................. --> 12288\n",
      "eeg_fn.bias................... --> 32\n",
      "\n",
      "Total Parameter Count:........ --> 45124\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "print_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training 2a model with all subjects and 2b weigths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/200, Loss: 42.40646207332611, Train accuracy: 35.17%, Test accuracy: 33.33%\n",
      "Epoch 20/200, Loss: 42.41975271701813, Train accuracy: 36.06%, Test accuracy: 32.18%\n",
      "Epoch 30/200, Loss: 42.033458948135376, Train accuracy: 35.76%, Test accuracy: 35.42%\n",
      "Epoch 40/200, Loss: 42.2812123298645, Train accuracy: 34.28%, Test accuracy: 33.56%\n",
      "Epoch 50/200, Loss: 41.92963111400604, Train accuracy: 34.97%, Test accuracy: 33.33%\n",
      "Epoch 60/200, Loss: 42.421858072280884, Train accuracy: 36.11%, Test accuracy: 33.56%\n",
      "Epoch 70/200, Loss: 42.07186138629913, Train accuracy: 35.12%, Test accuracy: 32.18%\n",
      "Epoch 80/200, Loss: 42.292325139045715, Train accuracy: 34.97%, Test accuracy: 33.56%\n",
      "Epoch 90/200, Loss: 42.151368141174316, Train accuracy: 36.36%, Test accuracy: 35.42%\n",
      "Epoch 100/200, Loss: 42.27779138088226, Train accuracy: 35.66%, Test accuracy: 34.49%\n",
      "Epoch 110/200, Loss: 41.98583507537842, Train accuracy: 34.82%, Test accuracy: 35.65%\n",
      "Epoch 120/200, Loss: 42.23501908779144, Train accuracy: 35.81%, Test accuracy: 34.95%\n",
      "Epoch 130/200, Loss: 42.18116521835327, Train accuracy: 35.86%, Test accuracy: 33.80%\n",
      "Epoch 140/200, Loss: 41.98086142539978, Train accuracy: 34.52%, Test accuracy: 37.73%\n",
      "Epoch 150/200, Loss: 41.84802973270416, Train accuracy: 34.47%, Test accuracy: 35.19%\n",
      "Epoch 160/200, Loss: 42.24988889694214, Train accuracy: 35.57%, Test accuracy: 33.80%\n",
      "Epoch 170/200, Loss: 42.19730842113495, Train accuracy: 35.71%, Test accuracy: 33.80%\n",
      "Epoch 180/200, Loss: 41.87514114379883, Train accuracy: 36.01%, Test accuracy: 35.19%\n",
      "Epoch 190/200, Loss: 42.05350971221924, Train accuracy: 35.27%, Test accuracy: 34.72%\n",
      "Epoch 200/200, Loss: 41.86336326599121, Train accuracy: 35.91%, Test accuracy: 33.10%\n",
      "##################################################\n",
      "Final_loss: 41.86336326599121\n",
      "Final train accuracy: 35.02%\n",
      "Final test accuracy: 34.72%\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=cfg['train']['learning_rate'], weight_decay=cfg['train']['weight_decay'])\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(cfg['train']['n_epochs']):\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    for batch_features, batch_labels in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_features[0], batch_features[1])\n",
    "        loss = criterion(outputs, batch_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    if epoch % 10 == 9:\n",
    "        train_accuracy = accuracy(model, train_dataloader)\n",
    "        test_accuracy = accuracy(model, test_dataloader)\n",
    "        print(f\"Epoch {epoch + 1}/{cfg['train']['n_epochs']}, Loss: {epoch_loss}, Train accuracy: {train_accuracy:.2f}%, Test accuracy: {test_accuracy:.2f}%\")\n",
    "\n",
    "print(\"#\"*50)\n",
    "print(f'Final_loss: {epoch_loss}')\n",
    "print(f'Final train accuracy: {accuracy(model, train_dataloader):.2f}%')\n",
    "print(f'Final test accuracy: {accuracy(model, test_dataloader):.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_state_2a_transfer_learning_all_subjects.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
