{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "from src.dataset.MI_dataset_single_subject import MI_Dataset as MI_Dataset_single_subject\n",
    "\n",
    "from config.default import cfg\n",
    "\n",
    "\n",
    "from models.conditioned_eegnet import ConditionedEEGNet\n",
    "\n",
    "from utils.eval import accuracy\n",
    "from utils.model import print_parameters\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subjects = [1,2,3,4,5,6]\n",
    "test_subjects = [7,8,9]\n",
    "train_runs = {\n",
    "                1:[0, 1, 2, 3, 4,5],\n",
    "                2:[0, 1, 2, 3, 4,5],\n",
    "                3:[0, 1, 2, 3, 4,5],\n",
    "                4:[0, 1,2],\n",
    "                5:[0, 1, 2, 3, 4,5],\n",
    "                6:[0, 1, 2, 3, 4,5]                \n",
    "        }\n",
    "test_runs = {\n",
    "                7:[0, 1, 2, 3, 4,5],\n",
    "                8:[1,2,3,4,5],\n",
    "                9:[1,2,3,4,5]\n",
    "}\n",
    "\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device =  torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "Train dataset: 1584 samples\n"
     ]
    }
   ],
   "source": [
    "train_datasets = []\n",
    "\n",
    "for subject in train_subjects:\n",
    "    dataset = MI_Dataset_single_subject(subject, train_runs[subject], return_subject_id=True, device=device, verbose=False)\n",
    "    train_datasets.append(dataset)\n",
    "    channels = dataset.channels\n",
    "    time_steps = dataset.time_steps\n",
    "train_dataset = ConcatDataset(train_datasets)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "print(f\"Train dataset: {len(train_dataset)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "25\n",
      "25\n",
      "Test dataset: 768 samples\n"
     ]
    }
   ],
   "source": [
    "test_datasets = []\n",
    "for subject in test_subjects:\n",
    "    test_datasets.append(MI_Dataset_single_subject(subject, test_runs[subject],return_subject_id=True, device=device, verbose=False))\n",
    "test_dataset = ConcatDataset(test_datasets)\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "print(f\"Test dataset: {len(test_dataset)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset: 1584 samples\n",
      "Test dataset: 768 samples\n",
      "torch.Size([64, 3, 401])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train dataset: {len(train_dataset)} samples\")\n",
    "print(f\"Test dataset: {len(test_dataset)} samples\")\n",
    "\n",
    "for feature, label in train_dataloader:\n",
    "    print(feature[0].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eeg_processor.conv1.weight.... --> 1024\n",
      "eeg_processor.bn1.weight...... --> 16\n",
      "eeg_processor.bn1.bias........ --> 16\n",
      "eeg_processor.dw_conv1.weight. --> 96\n",
      "eeg_processor.bn2.weight...... --> 32\n",
      "eeg_processor.bn2.bias........ --> 32\n",
      "eeg_processor.sep_conv1.weight --> 512\n",
      "eeg_processor.conv2.weight.... --> 1024\n",
      "eeg_processor.bn3.weight...... --> 32\n",
      "eeg_processor.bn3.bias........ --> 32\n",
      "subject_processor.fn1.weight.. --> 96\n",
      "subject_processor.fn1.bias.... --> 16\n",
      "query.weight.................. --> 12288\n",
      "key.weight.................... --> 512\n",
      "value.weight.................. --> 12288\n",
      "fn1.weight.................... --> 4096\n",
      "fn1.bias...................... --> 128\n",
      "fn2.weight.................... --> 512\n",
      "fn2.bias...................... --> 4\n",
      "eeg_fn.weight................. --> 12288\n",
      "eeg_fn.bias................... --> 32\n",
      "\n",
      "Total Parameter Count:........ --> 45076\n"
     ]
    }
   ],
   "source": [
    "model = ConditionedEEGNet( channels = channels, samples= time_steps, num_classes = 4)\n",
    "model.to(device)\n",
    "print_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConditionedEEGNet(\n",
      "  (eeg_processor): EEGNet(\n",
      "    (conv1): Conv2d(1, 16, kernel_size=(1, 64), stride=(1, 1), padding=(0, 32), bias=False)\n",
      "    (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (dw_conv1): Conv2d(16, 32, kernel_size=(3, 1), stride=(1, 1), groups=16, bias=False)\n",
      "    (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (activation): ELU(alpha=1.0)\n",
      "    (avg_pool1): AvgPool2d(kernel_size=(1, 4), stride=(1, 4), padding=0)\n",
      "    (dropout1): Dropout(p=0.5, inplace=False)\n",
      "    (sep_conv1): Conv2d(32, 32, kernel_size=(1, 16), stride=(1, 1), padding=(0, 8), groups=32, bias=False)\n",
      "    (conv2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (avg_pool2): AvgPool2d(kernel_size=(1, 8), stride=(1, 8), padding=0)\n",
      "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (subject_processor): FeedForward(\n",
      "    (fn1): Linear(in_features=6, out_features=16, bias=True)\n",
      "    (act): ELU(alpha=1.0)\n",
      "  )\n",
      "  (query): Linear(in_features=384, out_features=32, bias=False)\n",
      "  (key): Linear(in_features=16, out_features=32, bias=False)\n",
      "  (value): Linear(in_features=384, out_features=32, bias=False)\n",
      "  (fn1): Linear(in_features=32, out_features=128, bias=True)\n",
      "  (act1): ELU(alpha=1.0)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fn2): Linear(in_features=128, out_features=4, bias=True)\n",
      "  (eeg_fn): Linear(in_features=384, out_features=32, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/200, Loss: 31.80426251888275, Train accuracy: 36.11%\n",
      "Epoch 20/200, Loss: 32.11807405948639, Train accuracy: 33.14%\n",
      "Epoch 30/200, Loss: 31.69123125076294, Train accuracy: 36.36%\n",
      "Epoch 40/200, Loss: 32.04901099205017, Train accuracy: 34.72%\n",
      "Epoch 50/200, Loss: 31.984686851501465, Train accuracy: 35.98%\n",
      "Epoch 60/200, Loss: 31.990182399749756, Train accuracy: 34.79%\n",
      "Epoch 70/200, Loss: 31.802629351615906, Train accuracy: 33.90%\n",
      "Epoch 80/200, Loss: 31.799349188804626, Train accuracy: 35.61%\n",
      "Epoch 90/200, Loss: 32.042041301727295, Train accuracy: 34.47%\n",
      "Epoch 100/200, Loss: 32.09911668300629, Train accuracy: 34.34%\n",
      "Epoch 110/200, Loss: 31.986289381980896, Train accuracy: 31.88%\n",
      "Epoch 120/200, Loss: 32.12982439994812, Train accuracy: 34.03%\n",
      "Epoch 130/200, Loss: 31.931111216545105, Train accuracy: 33.84%\n",
      "Epoch 140/200, Loss: 31.95639967918396, Train accuracy: 33.21%\n",
      "Epoch 150/200, Loss: 31.923577547073364, Train accuracy: 36.11%\n",
      "Epoch 160/200, Loss: 31.925588250160217, Train accuracy: 35.10%\n",
      "Epoch 170/200, Loss: 31.813690781593323, Train accuracy: 35.23%\n",
      "Epoch 180/200, Loss: 31.830140829086304, Train accuracy: 34.34%\n",
      "Epoch 190/200, Loss: 31.72882628440857, Train accuracy: 36.55%\n",
      "Epoch 200/200, Loss: 31.883930444717407, Train accuracy: 34.15%\n",
      "##################################################\n",
      "Final_loss: 31.883930444717407\n",
      "Final train accuracy: 34.53%\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=cfg['train']['learning_rate'], weight_decay=cfg['train']['weight_decay'])\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(cfg['train']['n_epochs']):\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    for batch_features, batch_labels in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_features[0], batch_features[1])\n",
    "        loss = criterion(outputs, batch_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    if epoch % 10 == 9:\n",
    "        train_accuracy = accuracy(model, train_dataloader)\n",
    "        #test_accuracy = accuracy(model, test_dataloader)\n",
    "        print(f\"Epoch {epoch + 1}/{cfg['train']['n_epochs']}, Loss: {epoch_loss}, Train accuracy: {train_accuracy:.2f}%\")\n",
    "\n",
    "print(\"#\"*50)\n",
    "print(f'Final_loss: {epoch_loss}')\n",
    "print(f'Final train accuracy: {accuracy(model, train_dataloader):.2f}%')\n",
    "#print(f'Final test accuracy: {accuracy(model, test_dataloader):.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_state_all_subjectsv2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
